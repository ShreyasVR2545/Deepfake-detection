{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fea_hQfKp2Oe",
        "outputId": "3c15274f-13d4-4cbc-ca48-c5b70db842fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu3iWRRurZ8g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI-hgJHyrsdq",
        "outputId": "81fee986-ee71-47a4-fcb8-4a6f0bf450ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the dataset directory\n",
        "video_dir = '/content/drive/MyDrive/deepfake_dataset/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoB0bnebfYTx",
        "outputId": "5784e09c-5b1c-491f-a5da-615ff747ea8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1331 videos out of 1334\n",
            "Estimated remaining time: 0.01 hours\n",
            "Training data shape: (16, 299, 299, 3)\n",
            "Validation data shape: (4, 299, 299, 3)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "# Paths\n",
        "video_dir = '/content/drive/MyDrive/deepfake_dataset/'\n",
        "progress_path = '/content/drive/MyDrive/deepfake_progress.pkl'\n",
        "\n",
        "# Load metadata\n",
        "with open(os.path.join(video_dir, 'metadata.json')) as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# Function to extract frames from a video file\n",
        "def extract_frames(video_path, frames_per_video=5):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_interval = max(1, frame_count // frames_per_video)\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    for i in range(0, frame_count, frame_interval):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frame = cv2.resize(frame, (299, 299))\n",
        "            frames.append(frame)\n",
        "\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "# Process all videos to extract frames\n",
        "def process_videos(metadata, base_path, frames_per_video=5, start_idx=0):\n",
        "    frames = []\n",
        "    labels = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    total_videos = len(metadata)\n",
        "\n",
        "    for idx, (video_file, info) in enumerate(metadata.items()):\n",
        "        if idx < start_idx:\n",
        "            continue\n",
        "        if video_file.endswith('.mp4'):\n",
        "            video_path = os.path.join(base_path, video_file)\n",
        "            video_frames = extract_frames(video_path, frames_per_video)\n",
        "\n",
        "            for frame in video_frames:\n",
        "                frames.append(frame)\n",
        "                labels.append(1 if info['label'] == 'FAKE' else 0)\n",
        "\n",
        "        # Save progress and print progress\n",
        "        if idx % 10 == 0:  # Adjust this value to print progress more or less frequently\n",
        "            elapsed_time = time.time() - start_time\n",
        "            avg_time_per_video = elapsed_time / (idx - start_idx + 1)\n",
        "            remaining_videos = total_videos - idx - 1\n",
        "            estimated_remaining_time = avg_time_per_video * remaining_videos\n",
        "\n",
        "            print(f\"Processed {idx + 1} videos out of {total_videos}\")\n",
        "            print(f\"Estimated remaining time: {estimated_remaining_time / 3600:.2f} hours\")\n",
        "\n",
        "            # Save progress\n",
        "            progress = {\n",
        "                'frames': frames,\n",
        "                'labels': labels,\n",
        "                'last_processed_idx': idx\n",
        "            }\n",
        "            with open(progress_path, 'wb') as f:\n",
        "                pickle.dump(progress, f)\n",
        "\n",
        "    return np.array(frames) / 255.0, np.array(labels)\n",
        "\n",
        "# Check if there's saved progress\n",
        "if os.path.exists(progress_path):\n",
        "    with open(progress_path, 'rb') as f:\n",
        "        progress = pickle.load(f)\n",
        "        frames = progress['frames']\n",
        "        labels = progress['labels']\n",
        "        last_processed_idx = progress['last_processed_idx']\n",
        "else:\n",
        "    frames = []\n",
        "    labels = []\n",
        "    last_processed_idx = 0\n",
        "\n",
        "# Continue processing videos from the last saved progress\n",
        "X, y = process_videos(metadata, video_dir, start_idx=last_processed_idx)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the size of the data\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EtRQUDoFsVVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeNoeI9M9YCF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "# Define the model\n",
        "def create_model():\n",
        "    # Define input\n",
        "    input_data = Input(shape=(299, 299, 3), name='input_data')\n",
        "\n",
        "    # Base model using Xception\n",
        "    base_model = Xception(weights='imagenet', include_top=False, input_tensor=input_data, name='xception_base')\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
        "\n",
        "    # Add custom layers on top\n",
        "    x = Dense(1024, activation='relu', name='dense1')(x)\n",
        "    x = Dropout(0.5, name='dropout')(x)\n",
        "    output_layer = Dense(1, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "    # Define the full model\n",
        "    model = Model(inputs=input_data, outputs=output_layer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Paths to save the model\n",
        "model_path = '/content/drive/MyDrive/combined_model.keras'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BstZQajoAN2p"
      },
      "outputs": [],
      "source": [
        "# Load model if it exists, otherwise create a new one\n",
        "if os.path.exists(model_path):\n",
        "    model = load_model(model_path)\n",
        "else:\n",
        "    model = create_model()\n",
        "\n",
        "# Callbacks for training\n",
        "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# Assuming you have X_train, X_val, y_train, and y_val already prepared\n",
        "\n",
        "# Train the model\n",
        "try:\n",
        "    results = model.fit(\n",
        "        X_train, y_train,  # Providing training data\n",
        "        validation_data=(X_val, y_val),  # Providing validation data\n",
        "        batch_size=4, epochs=100,\n",
        "        callbacks=[checkpoint, early_stop]\n",
        "    )\n",
        "except RuntimeError as e:\n",
        "    print(f\"RuntimeError occurred: {e}\")\n",
        "    # Handle any additional error logging or recovery here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}